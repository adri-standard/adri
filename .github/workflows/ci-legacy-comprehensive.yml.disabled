name: CI Comprehensive - Full Test Suite

on:
  push:
    branches: [main]
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM UTC
  workflow_dispatch:
    inputs:
      run_performance_tests:
        description: 'Run performance benchmarks'
        required: false
        default: true
        type: boolean
      run_integration_tests:
        description: 'Run integration tests'
        required: false
        default: true
        type: boolean

env:
  PYTHON_VERSION: '3.11'
  CACHE_KEY_PREFIX: v2

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: false  # Let comprehensive tests complete

jobs:
  test-matrix:
    name: Test Matrix - Python ${{ matrix.python-version }}
    runs-on: ubuntu-latest
    timeout-minutes: 45

    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.10', '3.11', '3.12']

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ env.CACHE_KEY_PREFIX }}-pip-${{ runner.os }}-py${{ matrix.python-version }}-${{ hashFiles('**/pyproject.toml') }}
          restore-keys: |
            ${{ env.CACHE_KEY_PREFIX }}-pip-${{ runner.os }}-py${{ matrix.python-version }}-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev,test,security]"

      - name: Comprehensive test suite
        run: |
          echo "ðŸ§ª Running comprehensive test suite for Python ${{ matrix.python-version }}..."

          # Run CORE tests with coverage (focus on core ADRI functionality)
          pytest development/testing/tests/unit/ \
            --cov=adri \
            --cov-report=xml \
            --cov-report=term-missing \
            --cov-fail-under=85 \
            --tb=short \
            --maxfail=10 \
            -v

          echo "âœ… Core test suite completed"

      - name: Upload coverage reports
        uses: codecov/codecov-action@v4
        if: matrix.python-version == '3.11'
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
          token: ${{ secrets.CODECOV_TOKEN }}

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30
    if: github.event_name == 'push' || (github.event_name == 'workflow_dispatch' && inputs.run_integration_tests == 'true')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev,test]"

      - name: Framework integration tests
        run: |
          echo "ðŸ”— Running framework integration tests..."

          # Test with actual framework dependencies (mock mode)
          pytest tests/examples/integration_tests/ \
            -v \
            --tb=short \
            -m "not requires_api_key" \
            --maxfail=5

          echo "âœ… Integration tests completed"

  dependency-validation:
    name: Dependency Validation
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev,test]"

      - name: Dependency validation tests
        run: |
          echo "ðŸ“¦ Running dependency validation tests..."

          pytest tests/examples/dependency_tests/ \
            -v \
            --tb=short \
            --maxfail=3

          echo "âœ… Dependency validation completed"

  performance-benchmarks:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    timeout-minutes: 25
    if: github.event_name == 'push' || (github.event_name == 'workflow_dispatch' && inputs.run_performance_tests == 'true')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev,test]"

      - name: Load benchmark thresholds
        run: |
          echo "ðŸ“Š Loading performance thresholds..."
          if [ -f ".github/benchmark-thresholds.yml" ]; then
            cat .github/benchmark-thresholds.yml
          else
            echo "âš ï¸ No benchmark thresholds file found"
          fi

      - name: Run performance benchmarks
        run: |
          echo "âš¡ Running performance benchmarks..."

          # Run benchmark tests
          pytest development/testing/tests/test_benchmarks.py \
            --benchmark-only \
            --benchmark-json=benchmark_results.json \
            -v

          echo "âœ… Performance benchmarks completed"

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: benchmark_results.json
          retention-days: 30

  security-comprehensive:
    name: Comprehensive Security Scan
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev,test,security]"

      - name: Advanced security scanning
        run: |
          echo "ðŸ”’ Running comprehensive security analysis..."

          # Bandit security analysis
          bandit -r adri/ \
            -f json \
            -o bandit-report.json \
            --severity-level medium

          # Safety check for vulnerabilities (fix outdated CLI parameter)
          safety check --output json > safety-report.json

          # Pip audit for package vulnerabilities
          pip-audit --format=json --output=pip-audit-report.json

          echo "âœ… Security scanning completed"

      - name: Upload security reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: security-reports-comprehensive
          path: |
            bandit-report.json
            safety-report.json
            pip-audit-report.json
          retention-days: 90

  build-validation:
    name: Build & Distribution Validation
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install build tools
        run: |
          python -m pip install --upgrade pip
          pip install build twine

      - name: Build package
        run: |
          echo "ðŸ“¦ Building distribution packages..."
          python -m build

      - name: Validate distribution
        run: |
          echo "âœ… Validating built packages..."

          # Check package metadata
          twine check dist/*

          # Test wheel installation
          pip install dist/*.whl

          # Verify import and basic functionality
          python -c "
          import adri
          print(f'âœ… ADRI v{adri.__version__} imported successfully')

          # Basic functionality test
          from adri.core.assessor import DataQualityAssessor
          assessor = DataQualityAssessor()
          print('âœ… Core classes instantiated successfully')
          "

      - name: Upload distribution artifacts
        uses: actions/upload-artifact@v4
        with:
          name: distribution-packages
          path: dist/
          retention-days: 30

  # Final summary job
  comprehensive-success:
    name: âœ… Comprehensive CI Complete
    if: always()
    needs: [test-matrix, integration-tests, dependency-validation, performance-benchmarks, security-comprehensive, build-validation]
    runs-on: ubuntu-latest
    timeout-minutes: 3

    steps:
      - name: Check all jobs status
        run: |
          echo "ðŸ“Š Comprehensive CI Pipeline Results:"
          echo "Test Matrix: ${{ needs.test-matrix.result }}"
          echo "Integration Tests: ${{ needs.integration-tests.result }}"
          echo "Dependency Validation: ${{ needs.dependency-validation.result }}"
          echo "Performance Benchmarks: ${{ needs.performance-benchmarks.result }}"
          echo "Security Comprehensive: ${{ needs.security-comprehensive.result }}"
          echo "Build Validation: ${{ needs.build-validation.result }}"

          # Check CORE jobs (must pass - hard stop)
          if [[ "${{ needs.test-matrix.result }}" != "success" ||
                "${{ needs.performance-benchmarks.result }}" != "success" ||
                "${{ needs.security-comprehensive.result }}" != "success" ||
                "${{ needs.build-validation.result }}" != "success" ]]; then
            echo "âŒ CORE CI checks failed - blocking merge"
            exit 1
          fi

          # Check NON-CORE jobs (warnings only - don't block)
          if [[ "${{ needs.integration-tests.result }}" == "failure" ||
                "${{ needs.dependency-validation.result }}" == "failure" ]]; then
            echo "âš ï¸ NON-CORE checks failed - investigate but don't block merge"
            echo "Failed: Integration Tests and/or Dependency Validation (examples/demos)"
          fi

          echo "âœ… Comprehensive CI pipeline completed successfully!"

      - name: Generate summary report
        run: |
          echo "ðŸ“‹ **Comprehensive CI Summary**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Component | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|---------|" >> $GITHUB_STEP_SUMMARY
          echo "| Multi-Python Testing | ${{ needs.test-matrix.result == 'success' && 'âœ…' || 'âŒ' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Integration Tests | ${{ needs.integration-tests.result == 'success' && 'âœ…' || needs.integration-tests.result == 'skipped' && 'â­ï¸' || 'âŒ' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Dependency Validation | ${{ needs.dependency-validation.result == 'success' && 'âœ…' || 'âŒ' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Performance Benchmarks | ${{ needs.performance-benchmarks.result == 'success' && 'âœ…' || needs.performance-benchmarks.result == 'skipped' && 'â­ï¸' || 'âŒ' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Security Analysis | ${{ needs.security-comprehensive.result == 'success' && 'âœ…' || 'âŒ' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Build Validation | ${{ needs.build-validation.result == 'success' && 'âœ…' || 'âŒ' }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "*Comprehensive testing completed at $(date)*" >> $GITHUB_STEP_SUMMARY
